import os
import time
import json
import asyncio
import aiohttp
import redis.asyncio as redis
from fastapi import FastAPI, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.responses import HTMLResponse, JSONResponse
from contextlib import asynccontextmanager
from dotenv import load_dotenv

load_dotenv()

# --- Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ---
PB_URL = os.getenv("PB_URL", "http://127.0.0.1:8090")
BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379")

# Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Redis
redis_client = redis.from_url(REDIS_URL, decode_responses=True)

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø¬Ù„Ø³Ø© HTTP ÙˆØ§Ø­Ø¯Ø© ÙØ§Ø¦Ù‚Ø© Ø§Ù„Ø³Ø±Ø¹Ø© Ù…Ø¹ Connection Pooling
    connector = aiohttp.TCPConnector(limit=500, ttl_dns_cache=300)
    app.state.http_session = aiohttp.ClientSession(connector=connector)
    print("ğŸš€ Engine Started: Redis & HTTP Pool Ready")
    yield
    # ØªÙ†Ø¸ÙŠÙ Ø¹Ù†Ø¯ Ø§Ù„Ø¥ØºÙ„Ø§Ù‚
    await app.state.http_session.close()
    await redis_client.close()
    print("ğŸ’¤ Engine Stopped")

app = FastAPI(lifespan=lifespan)

# ØªÙØ¹ÙŠÙ„ Ø¶ØºØ· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ù†Ù‚Ù„
app.add_middleware(GZipMiddleware, minimum_size=1000)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© (Async + Cache) ---

async def get_cached_telegram_link(session: aiohttp.ClientSession, file_id: str):
    """
    Ø¬Ù„Ø¨ Ø±Ø§Ø¨Ø· Ø§Ù„ØµÙˆØ±Ø©.
    1. Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Redis (Ø³Ø±Ø¹Ø© Ù…ÙŠÙƒØ±Ùˆ Ø«Ø§Ù†ÙŠØ©).
    2. Ø¥Ø°Ø§ Ù„Ù… ÙŠÙˆØ¬Ø¯ØŒ Ø·Ù„Ø¨Ù‡ Ù…Ù† ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… ÙˆØ­ÙØ¸Ù‡ ÙÙŠ Redis.
    """
    cache_key = f"img:{file_id}"
    
    # 1. Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ù…Ù† Ø§Ù„ÙƒØ§Ø´
    try:
        cached_url = await redis_client.get(cache_key)
        if cached_url:
            return cached_url
    except Exception:
        pass # ØªØ¬Ø§Ù‡Ù„ Ø£Ø®Ø·Ø§Ø¡ Redis ÙˆØ§Ø³ØªÙ…Ø±

    # 2. Ø§Ù„Ø·Ù„Ø¨ Ù…Ù† ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… ÙÙŠ Ø­Ø§Ù„ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯Ù‡ ÙÙŠ Ø§Ù„ÙƒØ§Ø´
    if not BOT_TOKEN:
        return "https://via.placeholder.com/600x800?text=No+Token"

    api_url = f"https://api.telegram.org/bot{BOT_TOKEN}/getFile?file_id={file_id}"
    try:
        async with session.get(api_url) as resp:
            data = await resp.json()
            if data.get("ok"):
                file_path = data["result"]["file_path"]
                direct_url = f"https://api.telegram.org/file/bot{BOT_TOKEN}/{file_path}"
                
                # Ø­ÙØ¸ ÙÙŠ Redis Ù„Ù…Ø¯Ø© 55 Ø¯Ù‚ÙŠÙ‚Ø© (Ø±ÙˆØ§Ø¨Ø· ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… ØªÙ†ØªÙ‡ÙŠ Ø¨Ø¹Ø¯ Ø³Ø§Ø¹Ø©)
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Fire-and-forget Ù„Ù„Ø­ÙØ¸ Ù„Ø¹Ø¯Ù… ØªØ¹Ø·ÙŠÙ„ Ø§Ù„Ø±Ø¯
                asyncio.create_task(redis_client.setex(cache_key, 3300, direct_url))
                
                return direct_url
    except Exception as e:
        print(f"âš ï¸ Error fetching TG link: {e}")
    
    return "https://via.placeholder.com/600x800?text=Error"

# --- Endpoints ---

@app.get("/")
async def read_root():
    try:
        with open("index.html", "r", encoding="utf-8") as f:
            return HTMLResponse(content=f.read())
    except FileNotFoundError:
        return HTMLResponse("<h1>index.html not found</h1>", status_code=404)

@app.get("/series")
async def get_series(q: str = Query(None, min_length=1)):
    """
    Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø§Ù†Ø¬Ø§ Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„Ø¨Ø­Ø« ÙˆØªØ®Ø²ÙŠÙ† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø¤Ù‚ØªØ§Ù‹
    """
    session = app.state.http_session
    cache_key = f"api:series:{q if q else 'all'}"
    
    # ÙØ­Øµ Ø§Ù„ÙƒØ§Ø´ Ù„Ù„Ù†ØªØ§Ø¦Ø¬
    cached = await redis_client.get(cache_key)
    if cached:
        return JSONResponse(content=json.loads(cached))

    # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ù„Ù€ PocketBase
    params = {
        "sort": "-created",
        "fields": "id,title,cover_url"
    }
    if q:
        params["filter"] = f"title ~ '{q}'"
    
    try:
        async with session.get(f"{PB_URL}/api/collections/series/records", params=params) as resp:
            data = await resp.json()
            items = data.get("items", [])
            
            result = [{"id": r["id"], "title": r["title"], "cover_url": r["cover_url"]} for r in items]
            
            # Ø­ÙØ¸ Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¨Ø­Ø« Ù„Ù…Ø¯Ø© Ø¯Ù‚ÙŠÙ‚Ø© ÙˆØ§Ø­Ø¯Ø© Ù„ØªØ®ÙÙŠÙ Ø§Ù„Ø­Ù…Ù„
            await redis_client.setex(cache_key, 60, json.dumps(result))
            
            return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/chapters/{series_id}")
async def get_chapters(series_id: str):
    session = app.state.http_session
    # ÙƒØ§Ø´ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙØµÙˆÙ„ Ù„Ù…Ø¯Ø© 30 Ø«Ø§Ù†ÙŠØ© ÙÙ‚Ø· Ù„Ø£Ù†Ù‡Ø§ Ù‚Ø¯ ØªØªØ­Ø¯Ø«
    cache_key = f"api:chapters:{series_id}"
    
    cached = await redis_client.get(cache_key)
    if cached:
        return JSONResponse(content=json.loads(cached))

    params = {
        "filter": f'series_id="{series_id}"',
        "sort": "-chapter_number",
        "fields": "id,title,chapter_number"
    }

    try:
        async with session.get(f"{PB_URL}/api/collections/chapters/records", params=params) as resp:
            data = await resp.json()
            items = data.get("items", [])
            
            result = [{"id": r["id"], "title": r["title"], "chapter_number": r["chapter_number"]} for r in items]
            
            await redis_client.setex(cache_key, 30, json.dumps(result))
            return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/pages/{chapter_id}")
async def get_pages(chapter_id: str):
    session = app.state.http_session
    
    # 1. Ø¬Ù„Ø¨ Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ù…Ù„ÙØ§Øª Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    # Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„ÙƒØ§Ø´ Ù‡Ù†Ø§ Ø£ÙŠØ¶Ø§Ù‹ Ù„ØªÙ‚Ù„ÙŠÙ„ Ø·Ù„Ø¨Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    db_cache_key = f"db:pages:{chapter_id}"
    cached_records = await redis_client.get(db_cache_key)
    
    if cached_records:
        records = json.loads(cached_records)
    else:
        params = {
            "filter": f'chapter_id="{chapter_id}"',
            "sort": "page_number",
            "fields": "file_id"
        }
        async with session.get(f"{PB_URL}/api/collections/pages/records", params=params) as resp:
            data = await resp.json()
            records = data.get("items", [])
            # Ø­ÙØ¸ Ù‡ÙŠÙƒÙ„ Ø§Ù„ÙØµÙ„ ÙÙŠ Ø§Ù„ÙƒØ§Ø´ Ù„ÙØªØ±Ø© Ø·ÙˆÙŠÙ„Ø© (Ù…Ø«Ù„Ø§Ù‹ Ø³Ø§Ø¹Ø©)
            await redis_client.setex(db_cache_key, 3600, json.dumps(records))

    if not records:
        return {"pages": []}

    # 2. ØªØ­ÙˆÙŠÙ„ Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ù…Ù„ÙØ§Øª Ø¥Ù„Ù‰ Ø±ÙˆØ§Ø¨Ø· Ù…Ø¨Ø§Ø´Ø±Ø© (Ø¨Ø´ÙƒÙ„ Ù…ØªÙˆØ§Ø²ÙŠ ØµØ§Ø±ÙˆØ®ÙŠ)
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… gather Ù„ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø·Ù„Ø¨Ø§Øª ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù„Ø­Ø¸Ø©
    tasks = [get_cached_telegram_link(session, r["file_id"]) for r in records]
    urls = await asyncio.gather(*tasks)
    
    return {"pages": urls}

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙŠØ±ÙØ± (Ù„Ù„ØªØ·ÙˆÙŠØ± ÙÙ‚Ø·ØŒ ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ù…Ø± ÙÙŠ Ø§Ù„Ø£Ø³ÙÙ„)
if __name__ == "__main__":
    import uvicorn
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… uvloop Ù„Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)